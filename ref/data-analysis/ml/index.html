<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>ml | ST</title> <meta name="author" content="Sean Trautman"/> <meta name="description" content="Machine Learning"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/st-logo-transparent.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://straut12.github.io/ref/data-analysis/ml/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <div class="site-container"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">ST</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"></a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Coding</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/ref/coding/git/">VScode Github</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/coding/bash/">Bash Shell</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/coding/python/">Python</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/coding/js/">JavaScript</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/coding/html/">Web HTML</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Data Analysis</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/ref/data-analysis/data-collection/">data collection</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/data-analysis/databases/">databases</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/data-analysis/basic-charting/">basic charting</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/data-analysis/data-visualization/">data visualization</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/data-analysis/ml/">machine learning</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/data-analysis/statistics/">notes</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Linux</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/ref/linux/linuxdistros/">Linux Options</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/desktop/">Desktop Appearance</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/software/">Installing SW</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/sharing/">File Sharing</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/vnc-ssh/">Remote vnc ssh</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/terminal/">Terminal cli</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/autostart/">Autostart systemd</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/logs/">Logs</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/ref/linux/list/">List of SW to Install</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="site-body wrapper"> <aside class="site-sidebar" id="site-sidebar"> <nav class="toc"> <header><h4 class="toc__title">Table of Contents</h4></header> <ul class="toc__menu"> <li> <a href="#data-pre-processing">Data Pre-Processing</a> <ul> <li><a href="#import">Import</a></li> <li><a href="#scrub">Scrub</a></li> <li><a href="#encode-categorical-data">Encode Categorical Data</a></li> <li><a href="#training-and-test-sets">Training and Test Sets</a></li> <li><a href="#feature-scaling">Feature scaling</a></li> </ul> </li> <li> <a href="#modeling-regression">Modeling (Regression)</a> <ul> <li><a href="#multiple-linear-regression">Multiple Linear Regression</a></li> <li><a href="#polynomial-linear-regression">Polynomial Linear Regression</a></li> <li><a href="#support-vector-regression">Support Vector Regression</a></li> <li><a href="#decision-treerandom-forest-regression">Decision Tree/Random Forest Regression</a></li> </ul> </li> <li><a href="#evaluation-regression-r">Evaluation (Regression RÂ²)</a></li> <li> <a href="#modeling-classification">Modeling (Classification)</a> <ul> <li><a href="#logistic-regression">Logistic Regression</a></li> <li><a href="#k-nearest-neighbors-k-nn">K-Nearest Neighbors (K-NN)</a></li> <li><a href="#support-vector-machine-svm-kernel">Support Vector Machine (SVM) Kernel</a></li> <li><a href="#naive-bayes">Naive Bayes</a></li> <li><a href="#decision-treerandom-forest-classification">Decision Tree/Random Forest Classification</a></li> </ul> </li> <li><a href="#evaluation-classification-accuracy">Evaluation (Classification Accuracy)</a></li> <li> <a href="#unsupervised-learning">Unsupervised Learning</a> <ul> <li><a href="#k-means-clustering-model">K-means Clustering Model</a></li> <li><a href="#hierarchical-clustering-model">Hierarchical Clustering Model</a></li> <li><a href="#apriori-arl">Apriori (ARL)</a></li> <li><a href="#eclat-arl">Eclat (ARL)</a></li> </ul> </li> <li> <a href="#reinforcement-learning">Reinforcement Learning</a> <ul> <li><a href="#upper-confidence-bound-ucb">Upper Confidence Bound (UCB)</a></li> <li><a href="#thompson-sampling">Thompson Sampling</a></li> </ul> </li> </ul> </nav> </aside> <main> <div class="post"> <p class="post-description">Machine Learning</p> <article> <p>Although a significant amount of data analysis can be done with tools like graphs, box plots, paretos, and pivot tables; often there is a need for another layer. Notes below are geared toward sklearn models to help with quicker and deeper analysis of data.</p> <p>Examples below were ran with <strong>Python in Excel</strong><br> Defect signature detected on wafers. Second set of wafers show same signature but notch is rotated 90d.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/wafer-rotated.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Data table is a list of process and equipment that wafers were processed or inspected with and if the wafer had a defect signature or not (0=clean, 1=defect at notch, 2=defect at 90d). Analysis results from a few classification models (logistic regression, naive bayes, decision tree) highlighting the suspect tool.</p> <p><strong>Logistic Regression</strong><br> Only used binary (0=clean, 1=either defect signature) for the label. Results are for a small set of process/tools but it was repeated on a larger set with same results (50 process with 3 tools/process). Higher coefficient values highlight the suspect tool. However the interaction with the inspection tool is not brought out.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/wfr-rotated-lr.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Decision Tree</strong> <br> Decision tree worked best with only 2 defect classes (0=clean, 1=either defect signature) Results are for a small set of process/tools but it was repeated on a larger set with same results (50 process with 3 tools/process).</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/wfr-rotated-dt.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Naive Bayes</strong> <br> Naive Bayes works with multiple defect classes (0=clean, 1=defective at notch, 2=defect at -90d) Results are for a small set of process/tools but it was repeated on a larger set with same results (50 process with 3 tools/process). Suspect tools highlighted with log probability approaching 0. Naive Bayes was also able to highlight the Inspection interaction. When wafers were inspected they were returned rotated 90d so the resulting defects at the next process step were rotated 90d.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/excel-python-NB.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/wfr-rotated-nb.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>AI â&gt; ML â&gt; Deep Learning/Neural Nets</p> <p>AI - intelligent machines<br> ML - Machine Learning. Subset of AI algorithms which use data to learn and match patterns aka learn by example. Learn an approximate function that can be used to predict the response (dependent variable) <br> DL - Deep Learning. Subset of ML for more complex tasks. Math heavy.</p> <p><strong>Inference vs prediction</strong></p> <ul> <li>Prediction - Predict Y based on X (geared toward future prediction). Create the best model that can take in all the X features and predict Y with high accuracy (low error). What will my final CD be given this dose on this scanner with this etcher. <ul> <li>linear regression, decision trees, support vector machines</li> </ul> </li> <li>Inference is geared toward understanding the relationships and patterns between input and output variables. What impact do tools A, B and process C, D have on the yield. <ul> <li>logistic regression, bayesian</li> </ul> </li> </ul> <p><strong>Machine Learning</strong> <br> <a href="https://machine-learning-tutorial-abi.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Python Machine Learning</a></p> <p>Notes from udemy ML A-Z<br> Will be using scikit-learn which is easier to learn/use vs Tensorflow at the expense of being less powerful/flexible.</p> <p>General Steps for Regression or Classification</p> <ul> <li>Data pre-processing</li> <li>Build</li> <li>Train (may be iterative process where you tweak/tune parameters)</li> <li>Make predictions</li> <li>Calculate performance metrics</li> <li>Make a verdict</li> </ul> <p>Two types - Regression is when you predict a continuous real value. Classification is predicting a category. Regression models are listed first and then Classification.</p> <p>Some libraries using <a href="https://en.wikipedia.org/wiki/Scikit-learn" target="_blank" rel="noopener noreferrer">scikit</a> and <a href="https://docs.scipy.org/doc/scipy/tutorial/index.html#user-guide" target="_blank" rel="noopener noreferrer">scipy</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Pre-processing tools
</span><span class="kn">from</span> <span class="n">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>        <span class="c1"># Scrub data - populate empty cells with ave value of col
</span>
<span class="kn">from</span> <span class="n">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>   <span class="c1"># Categorical data tool
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span> <span class="c1"># Take a category with unique vals and create multi bin values (1,0,0 and 0,1,0 etc)
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>  <span class="c1"># Encode No/Yes into 0,1 
</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1"># Training and Test Sets
</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>  <span class="c1"># Scale the training set so data is in the same range
</span>
<span class="c1"># Regression Models for Continues Real Numbers
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>   <span class="c1"># Single/Multiple linear regression
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span> <span class="c1"># Used for Polynomial linear regression
</span><span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>                 <span class="c1"># Support vector regression
</span><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span> <span class="c1"># Decision tree regression
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span> <span class="c1"># Random forest
</span>
<span class="c1"># Classification Models for Categories
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span> <span class="c1"># Logistic regression
</span><span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span> <span class="c1"># K nearest neighbor
</span><span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>         <span class="c1"># Support Vector Classification
</span><span class="kn">from</span> <span class="n">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>  <span class="c1"># Naive Bayes
</span><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span> <span class="c1"># Decision tree
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span> <span class="c1"># Random forest
</span>               
<span class="c1"># Unsupervised learning algorithms (identify patterns in unlabeled data)
# Clustering
</span><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>   <span class="c1"># K means clustering
</span><span class="kn">import</span> <span class="n">scipy.cluster.hierarchy</span> <span class="k">as</span> <span class="n">sch</span>  <span class="c1"># Hierarchy clustering
</span><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>

<span class="c1"># Association Rule Learning
</span><span class="kn">from</span> <span class="n">apyori</span> <span class="kn">import</span> <span class="n">apriori</span>   <span class="c1"># apriori 
</span>
</code></pre></div></div> <h1 id="data-pre-processing">Data Pre-Processing</h1> <h2 id="import">Import</h2> <p>Features (independent variables) vs Dependent variable vector.</p> <ul> <li>Features/independent variables are the columns you use to predict the dependent variable (typically last column).</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Data.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span>  <span class="c1"># all rows/col except the last col (all feature/independent variables )
</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> <span class="c1"># dependent variable vector. last col
</span></code></pre></div></div> <h2 id="scrub">Scrub</h2> <p>What to do with bad/missing data</p> <ul> <li>Plot your data in a scatter plot or box plot to identify outliers. Drill down to the data point and see if you can determine obvious reasons for it being an outlier.</li> <li>Can simply leave it out if &lt;1%</li> <li>Use imputer module to replace it with average data from that column</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputer</span> <span class="o">=</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">missing_values</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
<span class="n">imputer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>  <span class="c1"># fit will look for missing values and calculate ave on X col 1,2
</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">imputer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># transform will perform the replacement
</span></code></pre></div></div> <h2 id="encode-categorical-data">Encode Categorical Data</h2> <p>Simple option is pandas get_dummies</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div> <p>OneHotEncoder will take a category col (ie a col with 3 unique tool IDs) and create multiple columns to represent them as 1/0. So a col with 3 unique tool IDs would become 3 col with 1,0,0 and 0,1,0 and 0,0,1</p> <p>ColumnTransformer takes 2 arg</p> <ol> <li>what kind of transformation and which index to perform it on</li> <li>remainder or which cols to keep that wonât have transformation applied</li> </ol> <p>Example below using âencoderâ transformation with OneHotEncoder class on column 0 which is string type. âpassthroughâ says to keep the columns that were not listed in the transform</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Remember to update the 3rd arg with the column to do OneHotEncoding on
</span><span class="n">ct</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span><span class="n">transformers</span><span class="o">=</span><span class="p">[(</span><span class="sh">'</span><span class="s">encoder</span><span class="sh">'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(),</span> <span class="p">[</span><span class="mi">0</span><span class="p">])],</span> <span class="n">remainder</span><span class="o">=</span><span class="sh">'</span><span class="s">passthrough</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">ct</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>  <span class="c1"># does fit and transform at same time. Must keep X as numpy array
</span></code></pre></div></div> <p>Nominal scale variables are labeled with no specific order. Ordinal scale the variables are in a specific order (ie, low income, mid income, high income or less than 50, 50-100, over 100 or dislike, neutral, like etc)</p> <p>Use label encoder to convert yes/no to 0/1</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># For single vector, dependent variable, use label encoder to convert yes/no to 0/1 (binary)
</span><span class="n">le</span> <span class="o">=</span> <span class="nc">LabelEncoder</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># does not have to be numpy array
</span></code></pre></div></div> <h2 id="training-and-test-sets">Training and Test Sets</h2> <p>Separating your data into two sets, training and test, allows you to compare the predicted values from the model to the actual values and generate accuracy scores, confusion matrix, etc. However if the data is limited and/or just searching for commonalities it is not necessary.</p> <p>A starting point is to use 80% for training and the remaining data for testing.</p> <p>Will create 4 sets.</p> <ul> <li>Pair of matrix features (Xtrain) and dependent variable (Ytrain) for train set.</li> <li>Pair of matrix features (Xtest) and dependent variable (Ytest) for test set.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># 80% observations go to training and 20% to test
# random_state=1 for learning so will return same set as tutorial
# random_state=0 for non tutorial
</span></code></pre></div></div> <h2 id="feature-scaling">Feature scaling</h2> <p>Scaling may be needed to normalize or standardize your data so one variable doesnât over power another (one col ranges from 500-10500 and another ranges from 1-50). Typically not used for a lot of regression models because the coeffecients can compensate for high values of features. But useful on other models. Also used if dependent variable is of different scale.</p> <p>Feature scaling is applied after split. Your test split is supposed to represent new data that you donât have until training is done so you donât want to modify it.</p> <p>Feature scaling always applied to columns (not row data across columns)</p> <ul> <li>Normalize values from 0-1 (Xnorm=(X-Xmin)/Xrange) # Works for normal distribution</li> <li>Standardize values from -3 to 3 except outliers (Xstand=(X-Xave)/Xstdev) # Works in most cases</li> </ul> <p>If data needs to be transformed into 2D array</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># pass number of rows and number of columns (ie 1)
</span></code></pre></div></div> <p>Standardization is a good choice since it works in most cases. (do not apply to category col)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sc</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>  <span class="c1"># will calculate mean/std dev of columns for standardization
# fit will get the mean/sigma
# transform will modify data
# Note - only get fit on the training set
</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:])</span> <span class="c1"># fit and transform. only apply to numerical col. Not the category in first 3 col
</span><span class="n">X_test</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:])</span> <span class="c1"># do not create new fit. but apply the scalar transform calculated on training set
</span></code></pre></div></div> <h1 id="modeling-regression">Modeling (Regression)</h1> <blockquote> <p>Linear vs non linear with respect to the class of regression/model refers to the coefficients (bâ, bâ), not the X feature. Can the model be expressed as a linear combination of coefficients. A non linear model would have bâ/(bâ+Xâ) where you can not replace the coefficients with other coefficients to solve for X.</p> </blockquote> <p>Details on concepts and 5 different methods</p> <ol> <li>All-in - Have prior knowledge or preparing for Backward Elimination</li> <li>Backward Elimination (* Stepwise Regression) <ol> <li>Select a significance level to STAY in the model (0.05)</li> <li>Fit the full model with all possible predictors</li> <li>Consider the predictor with hightest P value. If P &gt; SL go to next step, else finish (when all variables P &lt; SL then model is finished).</li> <li>Remove the predictor</li> <li>Fit model with this variable. You have to rebuild/refit the model with the fewer number of variables. Will get new coefficients/constants. Keep looping steps 3-5. Remove predictor with highest P val. Fit the model again with one less variable. Keep repeating until variable with highest P is less than the SL.</li> </ol> </li> <li>Forward Selection. Growing one variable at a time (* Stepwise Regression) <ol> <li>Select a SL to ENTER the model (SL= 0.05)</li> <li>Fit all simple regression models. Fit y to all the separate X features. Select the one with the lowest P value</li> <li>Keep this variable and fit all possible models with one extra predictor added to the one(s) you already have</li> <li>Consider the predictor with the lowest P-value. If P &lt; SL, go to step 3, else finish and keep the previous model before adding the last var.</li> </ol> </li> <li>Bidirectional Elimination - Combine methods 2-3 (** Stepwise Regression) <ol> <li>Select a SL to ENTER and to STAY in the model (.05)</li> <li>Perform the next step of Forward Selection (new var must have : P &lt; SLENTER to enter)</li> <li>Perform ALL steps of Backward Elimination (old variables must have P &lt; SLSTAY to stay)</li> <li>No new variables can enter and no old variables can exit</li> </ol> </li> <li>Score Comparison - All Possible Models <ol> <li>Select a criterion of goodness of fit</li> <li>Construct all possible regression models</li> <li>Select the one with the best criterion</li> </ol> </li> </ol> <blockquote> <p>LinearRegression class will iterate thru multiple features to find highest P value</p> </blockquote> <p><strong>Linear Regression</strong> Ã½=bâ+bâXâ</p> <ul> <li>Ã½ is dependent var (hat refers to a predictor)</li> <li>Xâ is independent var (feature)</li> <li>bâ is y-intercept (constant)</li> <li>bâ is slope coefficient</li> <li>1 X or feature</li> </ul> <p>Line is derived using ordinary least squares. Minimize error. Sum of squares.</p> <ul> <li>residual Æáµ¢=yáµ¢-Ã½áµ¢</li> <li>sum(yáµ¢-Ã½áµ¢)Â² is minimized</li> </ul> <p>Assumptions</p> <ul> <li>Linear relationship between Y and each X</li> <li>Equal variance (Homoscedasticity) - Can not show cone shape in variation or showing variation is dependent on X</li> <li>Normality of error distribution (Multivariate Normality) - If you look along the line of linear regression would want to see normal distribution.</li> <li>Independence (no autocorrelation) - No patterns in the data. ie stock market where previous prices affect future</li> <li>Lack of Multicollinearity - Predictors are not correlated to each other. See category example below.</li> <li>Outlier check</li> </ul> <p>Examples of linear regression, deviation to model fit, cubic polynomial fit, and unequal variation (relationship between the Y dependent variation and the X feature).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/chart.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/chart2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/chart3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/Heteroscedasticity.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=15462765" target="_blank" rel="noopener noreferrer">By Krishnavedala - Own work, CC BY-SA 3.0, </a> <a href="https://commons.wikimedia.org/w/index.php?curid=6457163" target="_blank" rel="noopener noreferrer">By Skbkekas - Own work, CC BY 3.0, </a> <a href="https://commons.wikimedia.org/w/index.php?curid=18064846" target="_blank" rel="noopener noreferrer">Heteroscedasticity By Q9 at the English-language Wikipedia, CC BY-SA 3.0,</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>   <span class="c1"># Single/Multiple linear regression
# Using LineaerRegression. Will avoid dummy variable issue
</span><span class="n">regressor</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span> <span class="c1"># Build linear regression model and create object
</span><span class="n">regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># Train on the training set using fit method
</span>
<span class="c1"># Predict method expect 2D array
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># Predict test results using predict method.
</span>
<span class="c1"># Plot training set
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># use plot to graph function, the regression line
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary vs Experience (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Years of Experience</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Plot test set
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># regression line between test and train will be the same. Could plot either
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary vs Experience (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Years of Experience</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Get value
# Predict method expect 2D array
</span><span class="nf">print</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">([[</span><span class="mi">12</span><span class="p">]]))</span> <span class="c1"># prediction for 12yr experience. 2D array
</span>
<span class="c1"># Print equation coefficients
</span><span class="nf">print</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="c1"># salary = 26816 + 9345(year experience)
</span>
</code></pre></div></div> <h2 id="multiple-linear-regression">Multiple Linear Regression</h2> <p>Ã½=bâ+bâXâ+bâXâ+..bâXâ + bâDâ</p> <ul> <li>More than 1 X feature.</li> <li>Do not need to apply feature scaling</li> <li>Do not need to test for linear regression assumptions. It will just show a lower score and you will need to pick a different model.</li> <li>Ã½ is dependent var</li> <li>Xâ is independent var (feature matrix) for each col or X</li> <li>bâ is y-intercept (constant)</li> <li>bâ is slope coefficient</li> <li>Dâ is category - need to find how many unique values are in the col and split into multiple Dummy binary Variable columns (0,1). This LinearRegression class will omit one of the dummy variable col. If you have 4 then include 3. If 2 then include 1. Why? If 2 unique values only include 1 dummy col, not both. D2=1-D1 so you have a case of independent variable predicting another is Multicollinearity.</li> </ul> <p>There are multiple columns/features and we can not visualize the multidimensional output so use vectors to compare. Compare vector of the predicted vs vector of the test set result.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Using LineaerRegression. 
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>   <span class="c1"># Single/Multiple linear regression
# Will also iterate thru multiple features to find highest P value
</span><span class="n">regressor</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span> <span class="c1"># Build linear regression model and create object
</span><span class="n">regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># Train on the training set using fit method
</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># Predict test results using predict method.
</span>
<span class="n">np</span><span class="p">.</span><span class="nf">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># numpy concactanate allows to concatenate vectors or arrays either horizontally or vertically. axis=0,1 for vert/horiz
# Will use it to concatanate vertically the predicted and real profits.
# Pass vector of predicted result and real result (y_pred and y_test)
# Use reshape to go from horiz to vert and 1 is for 1 col.
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Single prediction
# Predict method expect 2D array
</span><span class="nf">print</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">160000</span><span class="p">,</span> <span class="mi">130000</span><span class="p">,</span> <span class="mi">300000</span><span class="p">]]))</span>
<span class="sh">"""</span><span class="s">
double pair of square brackets.  </span><span class="sh">"</span><span class="s">predict</span><span class="sh">"</span><span class="s"> method expects 2D array as the format

1,0,0,160000,130000,300000âscalars
[1,0,0,160000,130000,300000]â1D array
[[1,0,0,160000,130000,300000]]â2D array
</span><span class="sh">"""</span>

<span class="c1"># Get coefficients
</span><span class="nf">print</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">Profit=86.6ÃDummy State 1â873ÃDummy State 2+786ÃDummy State 3+0.773ÃR&amp;D Spend+0.0329ÃAdministration+0.0366ÃMarketing Spend+42467.53
</span><span class="sh">"""</span>
</code></pre></div></div> <h2 id="polynomial-linear-regression">Polynomial Linear Regression</h2> <p>Ã½=bâ+bâXâ+bâXâÂ²+..bâXââ¿</p> <ul> <li>Now the X feature may be at a higher power. ie XâÂ² If degree of 2 then quadratic model, if degree of 3 then cubic model ..</li> <li>Polynomial linear regression is just a type of multiple linear regression. It is still a linear model</li> <li>X portion is not linear .. but Linear regression applies to the coefficients (b1) part. Trying determine the coefficients so can plug in varying X values and determine the output.</li> <li>The linear/non-linear refers to the coefficients (b) and if the function can be expressed as a linear combination of coefficients.</li> <li>Do not need to apply feature scaling</li> <li>Do not need to test for linear regression assumptions. It will just show a lower score and you will need to pick a different model.</li> <li>Ã½ is dependent var</li> <li>Xâ is independent var (feature matrix) for each col or X</li> <li>bâ is y-intercept (constant)</li> <li>bâ is slope coefficient</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>   <span class="c1"># Single/Multiple linear regression
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="c1"># Training the Linear Regression model on the whole dataset
</span><span class="n">lin_reg</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="c1"># X,y is not broken into train/test set because all data is being used to create the model.
# The goal is to determine salary between level 6 and 7 so want all the data for the model.
</span><span class="n">lin_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Training the Polynomial Regression model on the whole dataset
# X=position levels and Y=salaries
</span><span class="n">poly_reg</span> <span class="o">=</span> <span class="nc">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># enter the order. start with 2nd, 3rd, 4th
</span><span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly_reg</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">lin_reg_2</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">lin_reg_2</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  

<span class="c1"># Visualize the linear and polynomial results
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lin_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (Linear Regression)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position Level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lin_reg_2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_poly</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (Polynomial Regression)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Higher resolution and smoother curve
</span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">lin_reg_2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">poly_reg</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_grid</span><span class="p">)),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (Polynomial Regression)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Predict new results with linear regression
# Predict method expect 2D array
</span><span class="n">lin_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])</span>

<span class="c1"># Predict new results with polynomial regression
# Can not just enter X, but have to enter X, X^2, X^3, X^4
# This is in the X_poly or poly_reg.fit_transform(X)
</span><span class="n">lin_reg_2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">poly_reg</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]]))</span>

</code></pre></div></div> <h2 id="support-vector-regression">Support Vector Regression</h2> <p>Apply a buffer margin or tube where the error does not matter. But points outside the tube are support vectors and dictate the tube.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/svr-rbf.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=60632948" target="_blank" rel="noopener noreferrer">By Shiyu Ji - Own work, CC BY-SA 4.0,</a></p> <p>Example will have feature scaling. Job class feature was from 1-15 and dependent Y salary was 45k-1M so had to scale the variables.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># used to get array into 2D array with 1 col for standard scalar function
</span>
<span class="c1"># StandardScaler will calculate mean/std dev of columns for standardization
</span><span class="n">sc_X</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>   
<span class="n">sc_y</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sc_X</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># scale the X col feature and Y dependent var separately
</span><span class="n">y</span> <span class="o">=</span> <span class="n">sc_y</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">regressor</span> <span class="o">=</span> <span class="nc">SVR</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Gaussian radial basis function kernel
</span><span class="n">regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Need to reverse the scaling to get original scale
# predict method expect 2D array
</span><span class="n">sc_y</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sc_y</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sc_y</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (SVR)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Higher resolution
</span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span> <span class="nf">max</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sc_y</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">sc_y</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc_X</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_grid</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (SVR)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h2 id="decision-treerandom-forest-regression">Decision Tree/Random Forest Regression</h2> <p>CART (Classification and Regression Tree)<br> Scaling is not required since predictions from decision tree regression are resulting from successive splits of the data through nodes of the tree and not equations like other models. <br> Decision tree is not ideal for single feature data set. Best for many data cols.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">regressor</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])</span>

<span class="c1"># High resolution
</span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (Decision Tree Regression)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><strong>Random Forest</strong><br> Ensemble. Build a lot of decision trees. Instead of just getting one prediction you get a lot of predictions (500+). Average across the predictions.</p> <ol> <li>Pick at random K data points from training set</li> <li>Build the decision tree associated to these K data points</li> <li>Choose the number Ntree of trees you want to build and repeat steps 1-2</li> <li>For a new data point, make each one of Ntree trees predic the valueo of Y for the data point in question and assign the new data point the average across all of the predicted Y values.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="n">regressor</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])</span>

<span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Truth or Bluff (Random Forest Regression)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Position level</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h1 id="evaluation-regression-r">Evaluation (Regression RÂ²)</h1> <p>RÂ² can be used to compare models for model selection.<br> The better the linear fit matches the data in comparison to a simple average your RÂ² value will approach 1 (Sum of Squares for linear regression fit will be close to 0, 1-0=1)</p> <ul> <li>residual Æáµ¢=yáµ¢-Ã½áµ¢</li> <li>sum(yáµ¢-Ã½áµ¢)Â² is minimized</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/r-squared.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=11398293" target="_blank" rel="noopener noreferrer">By Orzetto - Own work, CC BY-SA 3.0,</a></p> <ul> <li>RÂ² &gt; 0.9 is good</li> <li>RÂ² &lt; 0.7 its marginal</li> <li>RÂ² ~ 0.4 is bad</li> </ul> <p>Ã½=bâ+bâXâ+bâXâ+..bâXâ</p> <p>As you add more features/col (Xâs) the SStot does not change but the SSres may decrease or stay the same. This is a problem because as you add more columns of data/features your RÂ² may appear to improve even though they may not be relevant or adding value.</p> <p>Could use adjusted RÂ².</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/adj-r-squared.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>n - sample size p - number of independent variables. as more variables add the RÂ² will actually decrease unless the new variable improves the fit.</p> <p>RÂ²adj = 1-(1-RÂ²)*(n-1)/(n-p-1) p - number of independent variables<br> n - sample size<br> As more variables added the RÂ² will actually decrease unless the new variable improves the fit.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="nf">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># NEED TO CHECK Radj formula below
</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span> <span class="mi">1</span><span class="o">-</span><span class="nf">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="p">)</span> <span class="o">*</span> <span class="p">(</span> <span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">/</span> <span class="p">(</span> <span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">)</span>
</code></pre></div></div> <p>len(X_test.columns) or X_test.shape[1] for number of values?</p> <p>Run your data through all models and compare RÂ²</p> <h1 id="modeling-classification">Modeling (Classification)</h1> <p>Classification is a ML method to identify the category of new observations based on training data.</p> <ul> <li> <strong>Logistic Regression</strong> predicts binary outcome (pass/fail)</li> <li> <strong>K-NN</strong> is pattern recognition algorithm that uses training datasets to find the k closest relatives in future examples.</li> <li> <strong>SVM kernel</strong> is multidimensional. Assigns a hyperplane that best separates the features.</li> <li> <strong>Naive Bayes</strong> calculates the possibility of whether a data point belongs within a certain category.</li> <li> <strong>Random Forest/Decision Tree</strong> - supervised learning algorithm that works like a flow chart. Separates data points into two similar categories at a time from the trunk to branches to leaves. Random forest averages the decision trees.</li> </ul> <h2 id="logistic-regression">Logistic Regression</h2> <p>Logistic Regression will give a probability. Can split into two categories &gt;50% or &lt; 50% and get a binary 0,1 output.<br> Logistic regression classifier is a linear classifier so the prediction boundary/line will be straight line.</p> <p>The features are weighted. And the weights are interpretable<br> Prefer the dependent/data labels are balanced. ie have equal number of 0âs and 1âs.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/logistic-regression.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=116449187" target="_blank" rel="noopener noreferrer">By Canley - Own work, CC BY-SA 4.0, </a></p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/logistic-regression2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># scaling
</span><span class="n">sc</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># do not create new fit. but apply the scalar transform calculated on training set
</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="n">coef_</span> <span class="c1"># To see the coefficients. Higher coeff: 1 Lower coeff: 0  
</span>
<span class="c1"># Predicting
</span><span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span> <span class="c1"># Have to use transform since model had scaled values used for training
</span>
<span class="c1"># print out a matrix of the prediction (Y predicted) vs the actual (Y test)
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Confusion Matrix
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
<span class="sh">"""</span><span class="s">
[[65  3]  # There are 65 correct predictions of 0 (3 incorrect)
 [ 8 24]] # There are 24 correct predictions of 1 (8 incorrect)
          # Total of 89 correct predictions
</span><span class="sh">"""</span>
<span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="c1"># accuracy score was 0.89 or 89% correct. There were 
# 100 samples in the test set. 65 + 24 = 89 (89% of 100)
</span>
<span class="c1"># Visualize training set
</span><span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Logistic Regression (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Visualize Test set
</span><span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Logistic Regression (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h2 id="k-nearest-neighbors-k-nn">K-Nearest Neighbors (K-NN)</h2> <p>Note - the color map visualizations only works for datasets with 2 features</p> <p>KNN is a nonlinear classifier</p> <ol> <li>Chose the number of K neighbors (5 is a good starting point)</li> <li>Take the K nearest neighbors of the new data point, according to the Euclidean distance sqrt(x^2+y^2)</li> <li>Among these K neighbors, count the number of data points in each category</li> <li>Assign the new data point to the category where you counted the most neighbors</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/knn.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=2170282" target="_blank" rel="noopener noreferrer">By Antti Ajanki AnAj - Own work, CC BY-SA 3.0, </a></p> <p>KNeighborsClassifier args</p> <ul> <li>5 is good starting point for K number of neighbors</li> <li>metric is the distance you want to use between observation point and neighbors. To use euclidean dist choose minkowski metric with p=2</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="sh">'</span><span class="s">minkowski</span><span class="sh">'</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># train it on the training set
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
<span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">K-NN (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">K-NN (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <h2 id="support-vector-machine-svm-kernel">Support Vector Machine (SVM) Kernel</h2> <p>Defines a support vector to separate groups or classes. Differs from traditional ML in that it focuses on observation points that are close to the boundary separating the classes vs focusing on observations that are safe, classic example of each class. SVMs select a decision boundary which maximizes the distance from the closest data points of all classes. The decision boundary provided by the SVMs can be referred to as the maximum margin hyperplane or the maximum margin classifier and it will search through this margin.</p> <ul> <li>SVR can use both linear and non-linear kernels. The kernel you choose will depend on the data complexity.</li> <li>SVR is different from standard linear regression because it finds a hyperplane that best fits the data points in a continuous space.</li> </ul> <p>Example below uses linear kernel assuming data is linearly separable</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train SMV model on the training set
</span><span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># using a linear kernel
</span><span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict a new result
</span><span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span>

<span class="c1"># Predicting the test set results
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Making the confusion matrix
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
<span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Visualize training set
</span><span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">SVM (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Visualize test set
</span><span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">SVM (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <p><strong>Kernel SVM</strong><br> Kernel trick - Why? Because taking a non linearly separable data set and mapping it to a higher dimension to get a linearly separable data set. Then invoking the SVM alogrithm, building a decision boundary for the data and projecting all of that back into the original dimensions is computer intensive.</p> <p>Non linear SVM</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/kernel-trick.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/svm.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=60458994" target="_blank" rel="noopener noreferrer">By Shiyu Ji - Own work, CC BY-SA 4.0, </a></p> <p><strong>Types of Kernel Functions</strong></p> <ul> <li>Gaussian aka radial basis of function kernel</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/rbf.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <ul> <li>Sigmoid</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/sigmoid.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=4310325" target="_blank" rel="noopener noreferrer">By Qef (talk) - Created from scratch with gnuplot, Public Domain,</a></p> <p>Linear model/separator</p> <ul> <li>in a 1 dimensional space it is a dot</li> <li>in a 2 dimensional space it is a line</li> <li>in a 3 dimensional space it is a hyperplane</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># radial basis of function is nonlinear
</span><span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># Train the kernel svm model on the training set
</span>
<span class="c1"># Predict a new result
</span><span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span>

<span class="c1"># Predicting the test set results
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Build confusion matrix
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
<span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Visualize the training set results
</span><span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Kernel SVM (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># visualize the test set results
</span><span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Kernel SVM (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p>Examples .. Logistic Regression, KNN, SVM_linear, SVM_kernel, Bayes</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/logistic-regression-plot.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/knn-plot.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/svm-linear-plot.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/svm-kernel-plot.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/bayes-plot.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="naive-bayes">Naive Bayes</h2> <p>Called Naive because you assume X and Y are not dependent when they may be. But it still works.<br> Bayes is a probabilistic type of classify because you first calculate the probabilities and then based on those probabilities assign the new point a class. The dependent/y does not need to be binary. Can have multiple classes.</p> <p>Gaussian NB would not work on binary features. For categorical features use the CategoricalNB model</p> <p>Bayes Theorem Example</p> <p>tool1: 60pph P(tool1)=60/100=0.6<br> <strong>tool2</strong>: 40pph P(<strong>tool2</strong>)=40/100=0.4</p> <p>out of all parts 1% are defective P(defect)=1%<br> out of all defective parts 50% from tool1 and 50% from tool2<br> P(tool1|defect) = 50%<br> P(<strong>tool2</strong>|defect) = 50%</p> <table> <tbody> <tr> <td>(</td> <td>means given)</td> </tr> </tbody> </table> <p>What is propability that a part produced by tool2 is defective?<br> P(defect|<strong>tool2</strong>)=P(<strong>tool2</strong>|defect)<em>P(defect)/P(<strong>tool2</strong>)<br> P(defect|<strong>tool2</strong>)=0.5</em>0.01/0.4 = 0.0125 (12,500ppm are defective)</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/bayes.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>example<br> 1 group walks<br> 1 group drives<br> X Y chart<br> P(walks|X)=P(X|walks)*P(walks)/P(X)</p> <ol> <li>Prior Probability= P(walks)</li> <li>Marignal Likelihood = P(X)</li> <li> <table> <tbody> <tr> <td>Likelihood = P(X</td> <td>walks)</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>Posterior Probability=P(walks</td> <td>X)</td> </tr> </tbody> </table> </li> </ol> <table> <tbody> <tr> <td>Compare P(walks</td> <td>X) vs P(drives</td> <td>X)</td> </tr> </tbody> </table> <p>Going to add a new observation to data set Calculate P(walks|X) first</p> <ol> <li>P(walks)=Total Walkers/Total Observations=10/30</li> <li>P(X)=What is the likelihood of any new random pt added to data set falling within the circle. The user selects the radius of the circle around the new data pt. Any points in the circle will be deemed similar to the observation being added. P(X)=Number of Similar Observations/Total Observations=4/30</li> <li> <table> <tbody> <tr> <td>P(X</td> <td>walks)=Same circle but now only working with data pts of the âwalksâ class. = Number of Similar Observations Among those who walk/total number of walkers = 3/10</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>P(walks</td> <td>X)=3/10 * 10/30 / 4/30 = 0.75</td> </tr> </tbody> </table> </li> </ol> <p>Calculate P(drives|X) second<br> P(drives|X)=1/20 * 20/30 / 4/30 = 0.25<br> .75 vs .25 or 75% change the person walks vs 25% change the person drives so will classify as a walker.</p> <table> <tbody> <tr> <td>For Compare P(walks</td> <td>X) vs P(drives</td> <td>X) the denominator of P(X) is in both equations so if only comparing can cancel it out and reduce to</td> </tr> <tr> <td>P(X</td> <td>walks)*P(walks) vs P(X</td> <td>drives) * P(drives)</td> </tr> </tbody> </table> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">GaussianNB</span><span class="p">()</span>
<span class="c1"># classifier = CategoricalNB() # if features are categorical
</span>
<span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="n">feature_log_prob_</span> <span class="c1"># NumPy array of the log-probabilities of # each feature for each class. The array is of shape (n_features, n_classes)
# Each array provides the empirical log probability of categories given the # respective feature and class, P(x_i|y).
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Naive Bayes (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Naive Bayes (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <p>When you have more than 2 classes It follows a similar/straight process as it always adds up to 1. If you have 3 classes and classify 1 and itâs greater than 50% you can assign that class, but if not you have to calculate for each to assign the classification.</p> <h2 id="decision-treerandom-forest-classification">Decision Tree/Random Forest Classification</h2> <p>CART - Classification (categories) vs regression (real numbers)</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/tree.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=90405437" target="_blank" rel="noopener noreferrer">By Gilgoldm - Own work, CC BY-SA 4.0,</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span> <span class="o">=</span> <span class="sh">'</span><span class="s">entropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># entropy or gini
</span><span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
<span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Decision Tree Classification (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Decision Tree Classification (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><strong>Random Forest Classification</strong> <br> Ensemble methods construct more than one decision tree</p> <ol> <li>Pick a random K data points from the training set</li> <li>Build a decision tree associated to those data points.</li> <li>Choose the number of Ntrees you want to build and repeat 1-2</li> <li>For a new data point make each one of your Ntrees predict the category to which the data points belongs and assign the new data point to the category that wins the majority vote.</li> </ol> <p>Start off with one tree and then build more trees based on randomly selected subsets of data. Then average the whole.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="sh">'</span><span class="s">entropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">87000</span><span class="p">]])))</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span>

<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
<span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Random Forest Classification (Training set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="kn">from</span> <span class="n">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">sc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()]).</span><span class="n">T</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X1</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">X2</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="nc">ListedColormap</span><span class="p">((</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Random Forest Classification (Test set)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Salary</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <h1 id="evaluation-classification-accuracy">Evaluation (Classification Accuracy)</h1> <ol> <li>Import data/scrub data</li> <li>Split data into training/test sets (optional)</li> <li>Feature scaling (optional)</li> <li>Train model on training set</li> <li>Generate confusion matrix <ul> <li>y_pred = classifier.predict(X_test)</li> <li>print(confusion_matrix(y_test, y_pred))</li> <li>accuracy_score(y_test, y_pred)</li> </ul> </li> </ol> <p>Run your data through all models and compare accuracy<br> Accuracy Rate = Correct/Total</p> <p>To convert data types when scikit needs int type</p> <ol> <li>y=y.astype(âintâ)</li> <li>y = train_data[âYâ].astype(âintâ)</li> <li>for i,x in enumerate(y_pred): y_pred[i]=x.astype(âintâ)</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/confusion-matrix.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Accuracy Paradox can be seen if all data in Ã½ moved from 1 to 0 (pos to neg) the accuracy rate could go up.</p> <p><strong>Cumulative Accuracy Profile (CAP)</strong> CAP curve analysis</p> <ul> <li>add example</li> <li>Curve/Area of perfect model (aáµ¨) and curve/area of a good model (aáµ£). AR = aáµ£/aáµ¨</li> <li>or look at 50% line on horz axis and look where it crosses the good model and get the value of vert axis there. <ul> <li>90-100% is too good (over fitting or one of the independent var is a post facto var and should be removed)</li> <li>80-90% is very good</li> <li>70-80% is good</li> <li>60-70% is poor</li> <li>less 60% is bad</li> </ul> </li> </ul> <h1 id="unsupervised-learning">Unsupervised Learning</h1> <p>Unsupervised learning algorithms (identify patterns in unlabeled data). The models do not need to be supervised using a training set.</p> <p>Supervised - you know what to predict<br> Unsupervised - you do not know what to predict</p> <p>Grouped into two categories</p> <ol> <li>clustering</li> <li>association rule learning (ARL)</li> </ol> <p><strong>Clustering Model</strong><br> Clustering works best with numerical data</p> <p>K-means</p> <ol> <li>Decide how many clusters</li> <li>Place a randomly placed centroi</li> <li>K-Means will assign each of the data points to the closest centroid</li> <li>Calculate center of mass, move centroids, do process again</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/kcluster.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://commons.wikimedia.org/w/index.php?curid=59409335" target="_blank" rel="noopener noreferrer">By Chire - Own work, CC BY-SA 4.0,</a></p> <p>K-means++ takes extra steps in placing the initial centroid to avoid Random initialization trap. Uses weighted random approach below</p> <ol> <li>first centroid is chosen at random</li> <li>for each remaining data point compute the distance D to the nearest out of already selected centroids</li> <li>choose next centroid among remaining data points using weighted random selection, weighted by D^2</li> <li>Repeat 2-3 until all k centroids have been selected</li> </ol> <p><strong>Build clustering models</strong></p> <h2 id="k-means-clustering-model">K-means Clustering Model</h2> <p>Most popular<br> Background is that a team wants to understand their customers better and identify patterns.<br> Since it is not known what to predict will create the dependent variable. Creating it in such a way that each of the values of this future dependent vriable being created are actually the classes of this dependent variable.</p> <p>There will not be a y var when importing. And will not split into training/test set since this implies a dependent var containg the real results. Which is not the case in this scenario.</p> <p>wcss (within cluster sum of squares) - the sum of the square distances between each observation point of the cluster and its central width</p> <p>Will use elbow method to find optimal number of clusters</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/numclusters.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Code</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Mall_Customers.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">4</span><span class="p">]].</span><span class="n">values</span>   <span class="c1"># In tutorial only impored last 2 columns purely for 2D visualisation reasons
</span>
<span class="c1"># Using the elbow method to find the optimal number of clusters
# Run the KMeans multiple times with varying number of clusters
# Using k-means++ to avoid random initialization trap
</span><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="n">wcss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">i</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="sh">'</span><span class="s">k-means++</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Train each one on the dataset with different cluster sizes
</span>    <span class="n">wcss</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">wcss</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">The Elbow Method</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of clusters</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">WCSS</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Use fit_predict method to train the K-means model on the dataset and return/create Y dependent y_kmeans
# chose 5 clusters based on elbow method
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="sh">'</span><span class="s">k-means++</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">y_kmeans</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_kmeans</span><span class="p">)</span> <span class="c1"># Don't forget starts at 0. So value of 0 is the 1st cluster, etc
</span>
<span class="c1"># Visualize the 5 clusters
# Call the X table where each row matches the cluster (y_kmeans == 0,1,2..) 
# and then use col 0 for X and col 1 for Y (remember only used last 2 col of table)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 3</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">cyan</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 4</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">magenta</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 5</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">yellow</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Centroids</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Clusters of customers</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Annual Income (k$)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Spending Score (1-100)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p>How to use the data<br> Could target high income/high spending cluster with new deals <br> Brainstorm ways of reaching high income/low spending cluster</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/cluster-plot.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h2 id="hierarchical-clustering-model">Hierarchical Clustering Model</h2> <p>Two types</p> <ol> <li>Agglomerative (bottom up)</li> <li>Divisive (top down)</li> </ol> <p>Will use Agglomerative</p> <ol> <li>Make each daa pt a single point cluster - that forms N clusters</li> <li>Take the two closest data points and make them one cluster - That form N-1 cluster</li> <li>Take the two closest data points and make them one cluster - That form N-2 cluster</li> <li>Repeat step 3 until there is only one cluster</li> </ol> <p>Important aspect is closeness of clusters</p> <ul> <li>For 2 points on a 2D plane have been using euclidean distance sqrt(x^2+y^2)</li> <li>For clusters can use distance of .. <ol> <li>closest points</li> <li>furthest points</li> <li>average distance</li> <li>centroids</li> </ol> </li> </ul> <p>Dendogram acts as the memory of the algorithm and will remember the steps of clustering to get the final result. Will build it first to find the optimal number of clusters. Hierarchical clustering metric uses within cluster variance.<br> Find the largest vertical distance between horiz lines and then count the clusters</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/dendogram.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Mall_Customers.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]].</span><span class="n">values</span>   <span class="c1"># only importing last 2 col to make visualizing easier
</span>
<span class="c1"># Build dendogram
</span><span class="kn">import</span> <span class="n">scipy.cluster.hierarchy</span> <span class="k">as</span> <span class="n">sch</span>
<span class="n">dendrogram</span> <span class="o">=</span> <span class="n">sch</span><span class="p">.</span><span class="nf">dendrogram</span><span class="p">(</span><span class="n">sch</span><span class="p">.</span><span class="nf">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ward</span><span class="sh">'</span><span class="p">))</span> <span class="c1"># use method of minimum variance
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Dendrogram</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Customers</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># X axis is observations or rows
</span><span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Euclidean distances</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Fit hierarchal class model using 5 clusters 
</span><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="n">hc</span> <span class="o">=</span> <span class="nc">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">affinity</span> <span class="o">=</span> <span class="sh">'</span><span class="s">euclidean</span><span class="sh">'</span><span class="p">,</span> <span class="n">linkage</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ward</span><span class="sh">'</span><span class="p">)</span>
<span class="n">y_hc</span> <span class="o">=</span> <span class="n">hc</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># fit and predict model
</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 3</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">cyan</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 4</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="sh">'</span><span class="s">magenta</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Cluster 5</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Clusters of customers</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Annual Income (k$)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Spending Score (1-100)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><strong>Association Rule Learning (ARL)</strong></p> <h2 id="apriori-arl">Apriori (ARL)</h2> <p>People who bought also bought .. Can you prove the result by using some prior knowledge<br> Support, Confidence, Lift steps</p> <ol> <li>set a minimum support and confidence <ul> <li>support: the support of A and B is the number of transactions containg A and B divided by total num of transactions</li> <li>confidence: can start with 0.8 and then lower if not enough rules returned</li> </ul> </li> <li>take all the subsets in transactions having higher support than minimum support</li> <li>take all the rules of these subsets having higher confidence than minimum confidence</li> <li>sort the rules by decreasing lift <ul> <li>lift: most relevant metric tomeasure the strength of a rule. the quality or relevance of a rule (confidence/support). good value is at least 3. below 3 and rule is not that relevant.</li> </ul> </li> </ol> <p>Lift is the metric for measuring the relevance of an association rule</p> <p>Association rules inside an ensemble of transactions. Note since this is association rules there is no training/test set or dependent variable</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">apyori</span> <span class="c1"># have to install apyori package
</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Market_Basket_Optimisation.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">transactions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7501</span><span class="p">):</span> <span class="c1"># data is rows of transactions so load into a list
</span>  <span class="n">transactions</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="nf">str</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)])</span>

<span class="c1"># Train apriori model on dataset
</span><span class="sh">"""</span><span class="s">
transactions: list of items created above
min_support: support for each rule. only compute rules with min support value.
             There were 7501 transactions weekly. 
             Let</span><span class="sh">'</span><span class="s">s say we only want to consider products that appear in at least 3 transactions/day or 21/weekly.
             So 21/7501 = ~3%
min_confidence: started with 0.8 but no rules returned. trial and error showed 0.2 returned decent number of rules
min_lift:  3 or above indicated a decent rule quality/relevance

Customer wanted scenarios of buy A and get B free. so 1 product on left hand side and 1 product on right hand side. Total of exactly 2.
min_length: min number of elements you want to have in your rule. left to right
max_length: max number of elements you want to have in your rule. left to right

If wanted to do flexible scenarios. But BOGO and buy 10 get 1 free. Then min=2 and max=11
</span><span class="sh">"""</span>
<span class="kn">from</span> <span class="n">apyori</span> <span class="kn">import</span> <span class="n">apriori</span>
<span class="n">rules</span> <span class="o">=</span> <span class="nf">apriori</span><span class="p">(</span><span class="n">transactions</span> <span class="o">=</span> <span class="n">transactions</span><span class="p">,</span> <span class="n">min_support</span> <span class="o">=</span> <span class="mf">0.003</span><span class="p">,</span> <span class="n">min_confidence</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">min_lift</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">min_length</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">max_length</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># apriori returns a generator. generator is a function that returns an iterator. An iterator is an object that can be used to iterate over a sequence of values.
</span>
<span class="n">results</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span> <span class="c1"># cast results from apriori to a list
</span><span class="n">results</span> <span class="c1"># print out
</span><span class="sh">"""</span><span class="s">
[elationRecord(items=frozenset({</span><span class="sh">'</span><span class="s">chicken</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">light cream</span><span class="sh">'</span><span class="s">}), support=0.0045, ordered_statistics=[OrderedStatistic(items_base=frozenset({</span><span class="sh">'</span><span class="s">light cream</span><span class="sh">'</span><span class="s">}), items_add=frozenset({</span><span class="sh">'</span><span class="s">chicken</span><span class="sh">'</span><span class="s">}), confidence=0.290, lift=4.84)]), [...]
</span><span class="sh">"""</span>
<span class="c1"># If customer buy light cream will have 29% chance of buying chicken (confidencee)
# The rule containing these 2 products appears in 0.45% of the transactions (support)
</span>

<span class="c1"># Organize the results list into a df
</span><span class="k">def</span> <span class="nf">inspect</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>                               <span class="c1"># step through all items in list
</span>    <span class="n">lhs</span>         <span class="o">=</span> <span class="p">[</span><span class="nf">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span> <span class="c1"># 
</span>    <span class="n">rhs</span>         <span class="o">=</span> <span class="p">[</span><span class="nf">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="n">supports</span>    <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="n">confidences</span> <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="n">lifts</span>       <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="k">return</span> <span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">supports</span><span class="p">,</span> <span class="n">confidences</span><span class="p">,</span> <span class="n">lifts</span><span class="p">))</span> <span class="c1"># takes two or more lists as arguments and returns a list where the elements of the same index in the lists are paired together
</span><span class="n">resultsinDataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="nf">inspect</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Left Hand Side</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Right Hand Side</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Support</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Confidence</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Lift</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Display results non sorted
</span><span class="n">resultsinDataFrame</span>

<span class="c1"># Display the results sorted by descending lifts
</span><span class="n">resultsinDataFrame</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Lift</span><span class="sh">'</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
Looking at highest lift indicates people who bought fromage blanc had a 24.5% change of buying honey.

Left Hand Side	    Right Hand Side	Support	    Confidence  Lift
3	fromage blanc	honey	        0.003333	0.245098	5.164271
0	light cream	    chicken	        0.004533	0.290598	4.843951
2	pasta	        escalope	    0.005866	0.372881	4.700812
8	pasta	        shrimp	        0.005066	0.322034	4.506672
</span><span class="sh">"""</span>

<span class="c1"># To get all items into a single dataframe column
</span><span class="n">allTrans</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">items</span><span class="sh">'</span><span class="p">:</span><span class="n">transactions</span><span class="p">})</span> <span class="c1"># each dataframe row will be a list which can be exploded in next step
</span><span class="n">allTrans</span> <span class="o">=</span> <span class="n">allTrans</span><span class="p">.</span><span class="nf">explode</span><span class="p">(</span><span class="sh">'</span><span class="s">items</span><span class="sh">'</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">nan</span><span class="sh">'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">).</span><span class="nf">dropna</span><span class="p">()</span>  <span class="c1"># replace the nan with NaN and drop them
</span>
<span class="kn">from</span> <span class="n">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">PercentFormatter</span>

<span class="n">itemCounts</span> <span class="o">=</span> <span class="n">allTrans</span><span class="p">[</span><span class="sh">'</span><span class="s">items</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span> <span class="c1"># get counts of the values. this returns a pandas series so convert to df in next step
</span><span class="n">itemCounts</span> <span class="o">=</span> <span class="n">itemCounts</span><span class="p">.</span><span class="nf">to_frame</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">()</span> <span class="c1"># convert series to df
</span>
<span class="n">itemCounts</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">items</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># rename option was not working so used .columns to oupdate column names
</span>
<span class="c1"># calculate the cumulative percent of each unique item
</span><span class="n">itemCounts</span><span class="p">[</span><span class="sh">'</span><span class="s">cumperc</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">itemCounts</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">].</span><span class="nf">cumsum</span><span class="p">()</span><span class="o">/</span><span class="n">itemCounts</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span>
<span class="nf">print</span><span class="p">(</span><span class="n">itemCounts</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">itemCounts</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># use nlargest to get the top 10 'count' values
</span><span class="n">top10</span> <span class="o">=</span> <span class="n">itemCounts</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span> <span class="p">)</span>
<span class="c1">#top10['items'].value_counts().plot(ax=ax, kind='bar')  # if didn't need top 10 could just plot all counts of items without using nlargest
#top10.plot(ax=ax, kind='bar')  # some quick plotting for simple bar chart
</span>
<span class="c1"># to get bar plot with cumulative line chart
#define aesthetics for plot
</span><span class="n">color1</span> <span class="o">=</span> <span class="sh">'</span><span class="s">steelblue</span><span class="sh">'</span>
<span class="n">color2</span> <span class="o">=</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span>
<span class="n">line_size</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">top10</span>
<span class="c1">#create basic bar plot
#plt.rcParams["figure.figsize"] = [7.50, 3.50]
#plt.rcParams["figure.autolayout"] = True
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">items</span><span class="sh">'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

<span class="c1">#add cumulative percentage line to plot
</span><span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">twinx</span><span class="p">()</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cumperc</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="n">line_size</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_major_formatter</span><span class="p">(</span><span class="nc">PercentFormatter</span><span class="p">())</span>

<span class="c1">#specify axis colors
</span><span class="n">ax</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">color1</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">color2</span><span class="p">)</span>

<span class="c1">#display Pareto chart
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="sh">"""</span><span class="s">
plt. subplots() is popular because it gives you an Axes object and allows you to use the Axes interface to define plots.
fig, axes = plt.subplots(nrows=2, ncols=3)  # default args is 1, 1
  fig is the figure object
  axes is a list of axes objects, one for each subplot
  nrows is the number of rows in the grid
  ncols is the number of columns in the grid

The line of code fig, ax = plt.subplots() is a shortcut for creating a new figure and a set of subplots. The fig refers to the entire figure or window that contains the plot(s). 
 The ax refers to the axes, which are the canvas you draw on. 
 The subplots() method provides a way to plot multiple plots on a single figure. 
You can use plt.subplots() to make all their subplots at once. It returns the figure and axes as a tuple. For example, fig, ax = plt.subplots(2,1) creates a subplot with 2 rows and 1 column.

</span><span class="sh">"""</span>
</code></pre></div></div> <h2 id="eclat-arl">Eclat (ARL)</h2> <p>Similar to apriori, if you like A you might like B<br> But instead of lift describing the strength of a rule will only consider support in terms of sets. For A,B,C take transactions containing products A,B,C divided by total num of transactions</p> <blockquote> <p>usually would just use apriori instead of eclat</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># follow apriori instructions
# just remove confidence and lifts
# and since there are no rules replace with Product1 and Product2. not considering left vs right hand side
</span>
<span class="k">def</span> <span class="nf">inspect</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="n">lhs</span>         <span class="o">=</span> <span class="p">[</span><span class="nf">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="n">rhs</span>         <span class="o">=</span> <span class="p">[</span><span class="nf">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="n">supports</span>    <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="k">return</span> <span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">supports</span><span class="p">))</span>
<span class="n">resultsinDataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="nf">inspect</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Product 1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Product 2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Support</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Display by descending supports
</span><span class="n">resultsinDataFrame</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Support</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">"""</span><span class="s">
    Product 1	    Product 2	    Support
4	herb &amp; pepper	ground beef	    0.015998
7	whole wheat pasta	olive oil	0.007999
2	pasta	        escalope	    0.005866
1	mushroom cream sauce	escalope	0.005733
5	tomato sauce	ground beef	    0.005333
8	pasta	        shrimp	        0.005066
0	light cream	    chicken	        0.004533
3	fromage blanc	honey	        0.003333
</span><span class="sh">"""</span>
</code></pre></div></div> <h1 id="reinforcement-learning">Reinforcement Learning</h1> <p>Branch of ML moving in direction of AI and robotics. Used to solve interacting problems where the data observed up to time t is considered to decide which action to take at time t + 1. It is also used for Artificial Intelligence when training machines to perform tasks such as walking. Desired outcomes provide the AI with reward, undesired with punishment. Machines learn through trial and error.</p> <h2 id="upper-confidence-bound-ucb">Upper Confidence Bound (UCB)</h2> <p>UCB is a deterministic algorith. Choose the path with the highest upper confidence bound.</p> <p>multi-armed bandit problem</p> <ol> <li>we have D arms. Arms are ads that we display to users each time they connect to a web page</li> <li>each time a user visits this page, thatâs a round.</li> <li>at each round ânâ, we choose one ad to display.</li> <li>at each round n, ad i gives reward ri(n) {0,1}: ri(n)=1 if the user clicked on the ad i, 0 if the user didnât</li> <li>our goal is to maximize the total reward we get over many rounds</li> </ol> <p>Confidence Intervals used for</p> <ol> <li>Differences between population means or proportions</li> <li>Estimates of variation among groups</li> </ol> <p>Scenario with ads<br> UCB will select an ad to show to the user and will record if they click yes (1) or no (0)<br> Simulation dataset has 10k users with which ads they would click on<br> Will compare UCB vs Thompson to see which one is fastest at finding the best ad real-time</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Ads_CTR_Optimisation.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Implementing UCB
</span><span class="kn">import</span> <span class="n">math</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>   <span class="c1"># Can vary this number to see how fast the UCB can find the ad with the highest click rate. (needed more than 500)
</span><span class="n">d</span> <span class="o">=</span> <span class="mi">10</span>     <span class="c1"># 10 different designed ads. Important assumption there is a fixed conversin rate
</span><span class="n">ads_selected</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Will populate over the rounds which one was selected. At the end will contain all the different ads selected at each round. 
</span><span class="n">numbers_of_selections</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">d</span> <span class="c1"># List of Ni(n)
</span><span class="n">sums_of_rewards</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">d</span>       <span class="c1"># List of Ri(n) Accumulated rewards for each of the ads
</span><span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>   <span class="c1"># Loop through all users n=user
</span>                        <span class="c1"># General concept is to select the ad with the highest conversion rate/max UCB
</span>    <span class="n">ad</span> <span class="o">=</span> <span class="mi">0</span>              
    <span class="n">max_upper_bound</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="nf">if </span><span class="p">(</span><span class="n">numbers_of_selections</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>  <span class="c1"># if ad dealing with has already been selected do Step 2 calcs
</span>            <span class="n">average_reward</span> <span class="o">=</span> <span class="n">sums_of_rewards</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">numbers_of_selections</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>        <span class="c1"># Step 2 calculation
</span>            <span class="n">delta_i</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">numbers_of_selections</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="c1"># Step 2 confidence interval
</span>            <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">average_reward</span> <span class="o">+</span> <span class="n">delta_i</span>                                <span class="c1"># Calculate UCB
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="n">upper_bound</span> <span class="o">=</span> <span class="mf">1e400</span>  <span class="c1"># By setting upper_bound to ~infinity will make sure each ad is cycled thru    
</span>                                        <span class="c1"># Trick to make sure all ads are cycled thru (should occur in first 10 rounds)
</span>        <span class="k">if</span> <span class="n">upper_bound</span> <span class="o">&gt;</span> <span class="n">max_upper_bound</span><span class="p">:</span>   <span class="c1"># Check if new max upper bound has been found
</span>            <span class="n">max_upper_bound</span> <span class="o">=</span> <span class="n">upper_bound</span>   <span class="c1"># Step 3
</span>            <span class="n">ad</span> <span class="o">=</span> <span class="n">i</span>                          <span class="c1"># Update ad to reflect this new ad with higher UCB
</span>    <span class="c1"># Update 
</span>    <span class="n">ads_selected</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">ad</span><span class="p">)</span> <span class="c1"># full list of all the ads selected over the rounds
</span>    <span class="n">numbers_of_selections</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># increment the number of selections for that ad so far
</span>    <span class="n">reward</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">ad</span><span class="p">]</span>  <span class="c1"># Access the data set and get the value for the user or n and ad (row/col). 0 or 1
</span>    <span class="n">sums_of_rewards</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">=</span> <span class="n">sums_of_rewards</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">+</span> <span class="n">reward</span>
    <span class="n">total_reward</span> <span class="o">=</span> <span class="n">total_reward</span> <span class="o">+</span> <span class="n">reward</span>

<span class="c1"># Visualize results
# Should show which ad was getting the highest click rate so the UCB started selecting it more
# Vary the N value above to see how fast it can still identify the ad with highest click rate (needs more than 500 users)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">ads_selected</span><span class="p">)</span>  <span class="c1"># the sequence of ads that were selected over the rounds. list of 10k elements
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Histogram of ads selections</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Ads</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of times each ad was selected</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h2 id="thompson-sampling">Thompson Sampling</h2> <p>Thompson sampling is a probabilistic algorithm. Consists of choosing the action that maximizes the expected reward with respect to a randomly drawn belief. But not trying to guess the distributions. Trying to mathematically explain what we think is going on.</p> <ul> <li>Create a hypothetical point that we think will be our expected return</li> <li>Take action that will trigger the distribution to spit out a real world value</li> <li>Adjust the models perception to incorporat the new value</li> <li>Will trigger more refining on the best option</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Ads_CTR_Optimisation.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="kn">import</span> <span class="n">random</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>   <span class="c1"># Can vary this number to see how fast
</span><span class="n">d</span> <span class="o">=</span> <span class="mi">10</span>     <span class="c1"># 10 different designed ads. Important assumption there is a fixed conversin rate
</span><span class="n">ads_selected</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Will populate over the rounds which one was selected. At the end will contain all the different ads selected at each round. 
</span><span class="n">numbers_of_rewards_1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">d</span> <span class="c1"># Ni^1(n) number of times the ad i got reward 1, up to round N
</span><span class="n">numbers_of_rewards_0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">d</span> <span class="c1"># Ni^0(n) number of times the ad i got reward 0, up to round N
</span><span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>  <span class="c1"># General concept is to select the ad with the highest conversion rate
</span>    <span class="n">ad</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">max_random</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>   <span class="c1"># betavariate will return random draw from the beta distribution 0-1
</span>        <span class="n">random_beta</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">betavariate</span><span class="p">(</span><span class="n">numbers_of_rewards_1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">numbers_of_rewards_0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">random_beta</span> <span class="o">&gt;</span> <span class="n">max_random</span><span class="p">:</span>
            <span class="n">max_random</span> <span class="o">=</span> <span class="n">random_beta</span>
            <span class="n">ad</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">ads_selected</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">ad</span><span class="p">)</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">ad</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">reward</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">numbers_of_rewards_1</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">=</span> <span class="n">numbers_of_rewards_1</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">numbers_of_rewards_0</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">=</span> <span class="n">numbers_of_rewards_0</span><span class="p">[</span><span class="n">ad</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">total_reward</span> <span class="o">=</span> <span class="n">total_reward</span> <span class="o">+</span> <span class="n">reward</span>

<span class="c1"># Can find the optimal ad (highest conversion rate) in less than 500 rounds. UCB required 500 or more.
</span>
<span class="c1"># Visualize
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">ads_selected</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Histogram of ads selections</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Ads</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of times each ad was selected</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <p><strong>UCB vs Thompson Sampling</strong><br> <strong>UCB</strong></p> <ul> <li>deterministic algorithm. When you get a value you look at the upper confidence bound and continue with the one that is highest. Thereâs no randomness in the algorithm itself.</li> <li>If you rerun an iteration in the UCB algorithm after receiving the previous value it will always give the same result.</li> <li>Requires update at every round. Can not proceed to next round until you incorporate the value</li> </ul> <p><strong>Thompson</strong></p> <ul> <li>probabilistic alogrithm. In the algorithim itself it has distributions which represent where we think the actual expected returns are. Therefore every time we iterate we generate random values from those distributions.</li> <li>If you rerun an iteration after receiving the previous value it will always be different becaues weâre sampling from the distributions which characterize our perception of the world.</li> <li>Does not require update each round. Can accommodate delayed feedback. Can update in a batch manner. If for some reason you will not know the results until 100 rounds later you can still run the algorithm because youâll get a new set of hypothetical results generated in a probabilistic manner (even without updating your perception of the world).</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/coding/UCBvsThompson.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><a href="https://www.udemy.com/share/101Wci3@fIpzabLTJizOhW5Z7f5nTLyiMam_1ctmhB0flC5at1HREDxUsdwvIF8jj1lHXAOa/" target="_blank" rel="noopener noreferrer">Machine Learning A-Z</a></p> </article> </div> </main> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 Sean Trautman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>